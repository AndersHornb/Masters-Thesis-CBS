import os
import ollama
import pandas as pd
import re
import json
import tiktoken
import google.generativeai as genai
from tqdm import tqdm

# KONFIGURATION
DOKUMENT_MAPPE = r"C:\Users\ander\OneDrive\Skrivebord\Webscraping\Er sendt til AI"
OUTPUT_FIL = "ipo_sentiment_resultater2.csv"
TOKEN_LIMIT = 1000000
OVERLAP = 100

# Funktion til at tælle tokens
def count_tokens(text):
    enc = tiktoken.get_encoding("cl100k_base")
    return len(enc.encode(text))

# Funktion til at opdele lange sektioner i bidder med overlap
def split_into_chunks(text, max_tokens=TOKEN_LIMIT, overlap=OVERLAP):
    words = text.split()
    chunks = []
    current_chunk = []
    token_count = 0

    for word in words:
        token_count += count_tokens(word)
        current_chunk.append(word)

        if token_count >= max_tokens - overlap:
            chunks.append(" ".join(current_chunk))
            current_chunk = current_chunk[-overlap:]
            token_count = count_tokens(" ".join(current_chunk))

    if current_chunk:
        chunks.append(" ".join(current_chunk))
    
    return chunks

import time

# Set up Gemini API key
genai.configure(api_key="AIzaSyC6Zzzagc7lGjHGhP8d1Jxmtk-OyAPJcBQ")

# Global variable to track request count
request_count = 0
start_time = time.time()

def check_rate_limit():
    """Ensures we stay within Gemini API's 15 requests per minute limit."""
    global request_count, start_time

    # If 15 requests have been made, wait for 60 seconds
    if request_count >= 10:
        elapsed_time = time.time() - start_time
        if elapsed_time < 60:
            wait_time = 60 - elapsed_time
            print(f"Rate limit reached! Sleeping for {wait_time:.2f} seconds...")
            time.sleep(wait_time)

        # Reset counter and timer
        request_count = 0
        start_time = time.time()


# Funktion til at analysere tekst med Gemini
import re

# Set up Gemini API key
genai.configure(api_key="AIzaSyC6Zzzagc7lGjHGhP8d1Jxmtk-OyAPJcBQ")

def evaluer_tekst(tekst, sektion):
    """Sends text to Gemini API and extracts a numeric sentiment score (0-100)."""
    global request_count

    prompt = f"""
    You are analyzing an S-1 filing document section titled "{sektion}". Please return a number from 0-100 highlighting the sentiment in the text.

    Please only return a number between 0 and 100.

    {tekst}
    """

    try:
        check_rate_limit()  # Ensure we don't exceed rate limit
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)
        
        # Increment request counter only on successful response
        request_count += 1

        vurdering = response.text.strip()
        print(f"Model output for {sektion}:\n{vurdering}\n")

        # Extract only a number between 0-100
        match = re.search(r"\b\d{1,3}\b", vurdering)
        if match:
            score = int(match.group(0))
            if 0 <= score <= 100:
                return score
            else:
                print(f"❌ Invalid score {score}, returning None.")
                return None

        print(f"❌ Could not find a number in output: {vurdering}, returning None.")
        return None

    except Exception as e:  # ✅ FIXED INDENTATION
        print(f"Error processing text: {e}")
        return None  # ✅ FIXED INDENTATION


# Funktion til at behandle et dokument

def process_document(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        text = f.read()

    # Finder sektionen ud fra filnavnet
    filename = os.path.basename(file_path)

    if "risk_factors" in filename:
        sektion = "Risk Factors"
        print(f"Behandler {filename} som {sektion}...")
        score = evaluer_tekst(text, sektion)
        return {"Filnavn": filename, "Sektion": sektion, "Score": score}
    else:
        print(f"❌ Kunne ikke identificere sektion i fil: {filename}")
        return None



# Håndtering af alle dokumenter i mappen
resultater = []
for filnavn in tqdm(os.listdir(DOKUMENT_MAPPE)):
    if filnavn.endswith((".txt", ".html")):
        filsti = os.path.join(DOKUMENT_MAPPE, filnavn)
        print(f"Behandler: {filnavn}")
        resultater.append(process_document(filsti))

# Konverter til Pandas DataFrame
df = pd.DataFrame(resultater)

# Debugging: Udskriv de endelige resultater før de gemmes
print("Endelige data, der gemmes i CSV:")
print(df)

# Gem resultater til CSV
df.to_csv(OUTPUT_FIL, index=False)

print(f"Analyse færdig! Resultater gemt i {OUTPUT_FIL}")
